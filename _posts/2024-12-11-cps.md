---
title: Into CPS, never to return
layout: post
---

In the continuation-passing style (CPS) intermediate representation, there are
two rules: first, that function/operator arguments must always be *trivial*;
second, that function calls do not return. From this, a lot falls out.

In this post, we'll introduce CPS by building a simple (Plotkin) CPS transform
from a small Scheme-like language. We'll sketch some optimizations on the IR.
Then we'll look at a couple of the common ways to actually compile the IR for
execution.

## Mini-Scheme

We have integers: `5`

We have some operations on the integers: `(+ 1 2)`, `(< 3 4)` (returns 1 or 0)

We can bind variables: `(let ((x 1)) x)` / `(letrec ...)` ?

We can create single-parameter functions[^more-parameters]: `(lambda (x) (+ x 1))`

[^more-parameters]: It's a several-line change to the compiler to handle
    multiple parameters but for this post it's just noise so I leave it as an
    exercise.

We can call functions: `(f x)`

We can branch: `(if (< x y) x y)` (where we have decided to use 0 and 1 as
booleans)

## How do I...?

We're going to implement a recursive function called `cps` incrementally,
starting with the easy forms of the language and working up from there. Many
people like implementing the compiler both in Scheme and for Scheme but I find
that all the quasiquoting makes everything fussier than it should be and
obscures the lesson, so we're doing it in Python.

This means we have a nice clear separation of code and data. Our Python code is
the compiler and we'll lean on Python lists for S-expressions. Here's what some
sample Scheme programs might look like as Python lists:

```python
5

["+", 1, 2]

["let", [["x", 1]], "x"]

["lambda", ["x"], ["+", "x", 1]]
```

Our `cps` function will take two arguments. The first argument, `exp`, is the
expression to compile. The second argument, `k`, is a *continuation*. We have
to do *something* with our values, but CPS requires that functions never
returns. So what do we do? Call another function, of course.

This means that the top-level invocation of `cps` will be passed some useful
top-level continuation like `print-to-screen` or `write-to-file`. All child
invocations of `cps` will be passed either that continuation, a manufactured
continuation, or a continuation variable.

```python
cps(["+", 1, 2], "$print-to-screen")
# ...or...
cps(["+", 1, 2], ["cont", ["v"], ...])
```

So a continuation is just another function. Kind of.

While you totally can generate real first-class functions for use as
continuations, it can often be useful to *partition* your CPS IR by separating
them. All real (user) functions will take a continuation as a last
parameter---for handing off their return values---whereas continuations do no
such thing. TODO: write more

For this reason we syntactically distinguish IR function forms `["fun", ["x",
"k"], ["k", "x"]]` from IR continuation forms `["cont", ["x"], ["k", "x"]]`.
Similarly, we distinguish function calls `["f", "x"]` from continuation calls
`["$call-cont", "k", "x"]` (where `$call-cont` is a special form known to the compiler).

Let's look at how we compile integers into CPS:

```python
def cps(exp, k):
    match exp:
        case int(_):
            return ["$call-cont", k, exp]
    raise NotImplementedError(type(exp))  # TODO

cps(5, "k")  # ["$call-cont", "k", 5]
```

Integers satisfy the *trivial* requirement. To be trivial is to not require
"significant" (more than constant-time) evaluation. `5`, for example, requires
none at all; return it. `(lambda (x) ...)` requires only a heap
allocation[^allocation].

[^allocation]: Yes, allocations might not be constant-time because of garbage
    collection and stuff. But there's no metaphorical recursive call to the
    imaginary `eval` function.

Variables are similar. We leave the variable names as-is for now, so we need
not keep an environment parameter around.

```python
def cps(exp, k):
    match exp:
        case int(_) | str(_):
            return ["$call-cont", k, exp]
    raise NotImplementedError(type(exp))  # TODO

cps("x", "k")  # ["$call-cont", "k", "x"]
```

Now let's look at function calls. Function calls are the first type of
expression that requires recursively evaluating subexpressions. To evaluate `(f
x)`, for example, we need to first evaluate `f`, then `x`, then do a function
call.

To convert to CPS, we have to both do recursive compilation of the arguments
and also synthesize our first continuations!

To evaluate a subexpression, which could be arbitrarily complex, we have to
make a recursive call to `cps`. Unlike normal compilers, this doesn't return a
value. Instead, you pass it a continuation (does the word "callback" help
here?) to do future work when that value has a name. To generate
compiler-internal names, we have a `gensym` function that isn't interesting and
returns unique strings.

The only thing that differentiates it from, for example, a JavaScript callback,
is that it's not a Python function but instead a function in the generated
code.

```python
def cps(exp, k):
    match exp:
        case [func, arg]:
            vfunc = gensym()
            varg = gensym()
            return cps(func, ["cont", [vfunc],
                              cps(arg, ["cont", [varg],
                                        [vfunc, varg, k]])])
    # ...

cps(["f", 1], "k")
# ["$call-cont", ["cont", ["v0"],
#            ["$call-cont", ["cont", ["v1"],
#                       ["v0", "v1", "k"]],
#                     1]],
#          "f"]
```

Note that our generated function call from `(f x)` now also has a continuation
argument that was not there before. This is because `(f x)` does not *return*
anything, but instead passes the value to the given continuation.

Calls to primitive operators like `+` are our other interesting case. Like
function calls, we evaluate the operands recursively and pass in an additional
continuation argument. Note that not all CPS implementations do this for simple
math operators; some choose to allow simple arithmetic to actually "return"
values.

```python
def gensym(): ...

def cps(exp, k):
    match exp:
        case [op, x, y] if op in ["+", "-"]:
            vx = gensym()
            vy = gensym()
            return cps(x, ["cont", [vx],
                           cps(y, ["cont", [vy],
                                   [f"${op}", vx, vy, k]])])
    # ...

cps(["+", 1, 2], "k")
# ["$call-cont", ["cont", ["v0"],
#            ["$call-cont", ["cont", ["v1"],
#                       ["$+", "v0", "v1", "k"]],
#                     2]],
#          1]
```

We also create a special form for the operator in our CPS IR that begins with
`$`. So `+` gets turned into `$+` and so on. This helps distinguish operator
invocations from function calls.

Now let's look at creating functions. Lambda expressions such as `(lambda (x)
(+ x 1))` need to create a function at run-time and that function body contains
some code. To "return", we use `$call-cont` as usual, but we have to also
remember to create a new `fun` form with a continuation parameter (and then
thread that through to the function body).

```python
def cps(exp, k):
    match exp:
        case ["lambda", [arg], body]:
            vk = gensym("k")
            return ["$call-cont", k,
                        ["fun", [arg, vk], cps(body, vk)]]
    # ...

cps(["lambda", ["x"], "x"], "k")
# ["$call-cont", "k",
#                ["fun", ["x", "k0"],
#                        ["$call-cont", "k0", "x"]]]
```

Alright, last in this mini language is our `if` expression: `(if cond iftrue
iffalse)` where all of `cond`, `iftrue`, and `iffalse` can be arbitrarily
nested expressions. This just means we call `cps` recursively three times.

We also add this new compiler builtin called `($if cond iftrue iffalse)`
that takes one trivial expression---the condition---and decides which of the
branches to execute. This is roughly equivalent to a machine code conditional
jump.

The straightforward implementation works just fine, but can you see what might
go wrong?

```python
def cps(exp, k):
    match exp:
        case ["if", cond, iftrue, iffalse]:
            vcond = gensym()
            return cps(cond, ["cont", [vcond],
                                ["$if", vcond,
                                   cps(iftrue, k),
                                   cps(iffalse, k)]])
# ...

cps(["if", 1, 2, 3], "k")
# ["$call-cont", ["cont", ["v0"],
#                  ["$if", "v0",
#                              ["$call-cont", "k", 2],
#                              ["$call-cont", "k", 3]]],
#                1]
```

The problem is that our continuation, `k`, need not be a continuation
variable---it could be an arbitrary complicated expression. Our implementation
copies it into the compiled code *twice*, which in the worst case could lead to
exponential program growth. Instead, let's bind it to a name and then use the
name twice.

```python
def cps(exp, k):
    match exp:
        case ["if", cond, iftrue, iffalse]:
            vcond = gensym()
            vk = gensym("k")
            return ["$call-cont", ["cont", [vk],
                        cps(cond, ["cont", [vcond],
                                      ["$if", vcond,
                                        cps(iftrue, vk),
                                        cps(iffalse, vk)]])],
                        k]
# ...

cps(["if", 1, 2, 3], "k")
# ["$call-cont", ["cont", ["k1"],
#                  ["$call-cont", ["cont", ["v0"],
#                                   ["$if", "v0",
#                                     ["$call-cont", "k1", 2],
#                                     ["$call-cont", "k1", 3]]],
#                                   1]],
#                  "k"]
```

* alphatisation gives you SSA-like

## Meta-continuations

Now, you might have noticed that we're giving names to a lot of trivial
expressions---unnecessary `cont` forms used like `let` bindings. Why name the
integer `3` if it's trivial?

One approach people take to avoid this is *meta-continuations* (TODO: name
check). Instead of always generating `cont`s, we can sometimes pass in a
compiler-level (in this case, Python) function instead.

TODO: demo

This approach, though occasionally harder to reason about and more complex,
cuts down on a significant amount of code before it is ever emitted. For
few-pass compilers, for resource-constrained environments, for enormous
programs, ... this makes a lot of sense.

Another approach, potentially easier to reason about, is to lean on your
optimizer. You'll probably want an optimizer anyway, so you might as well use
it to cut down your intermediate code too.

* Olin Shivers and "functions rule the world" guy
* Hedgehog knows one great thing

## Optimizations

constant-folding

```python
["$+", "3", "4", "k"]  # => ["$call-cont", "k", 7]
["$if", 1, "t", "f"]  # => t
["$if", 0, "t", "f"]  # => f
```

beta reduction (TODO: caveats about renaming/alphatisation)
TODO: # occurrences/triviality/side effects

```python
["$call-cont", ["cont", ["k1"],
                 ["$call-cont", ["cont", ["v0"],
                                  ["$if", "v0",
                                    ["$call-cont", "k1", 2],
                                    ["$call-cont", "k1", 3]]],
                                  1]],
                 "k"]

# into
["$call-cont", ["cont", ["v0"],
                 ["$if", "v0",
                   ["$call-cont", "k", 2],
                   ["$call-cont", "k", 3]]],
                 1]

# into
["$if", 1,
  ["$call-cont", "k", 2],
  ["$call-cont", "k", 3]]

# into
["$call-cont", "k", 2]
```

anchor pointing (?)

more advanced stuff like loop invariant code motion

## To C, perhaps to XYZ

* Out of CPS?
  * to SSA (the paper)
  * trampolines
  * one big switch
  * cheney on the mta
