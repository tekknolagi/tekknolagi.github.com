---
title: Parsing to IR and lvalues
layout: post
---

I don't want an AST in my hobby compiler. I'm not going to use it for
analysis---it would just be a stepping stone representation on the way to the
thing I really want, which is an SSA CFG. So I decided to parse straight from
tokens into an SSA IR.

I've always been a little nervous around parsers so I decided to lean into it
and get familiar with precedence climbing. I'd already written [something
similar][diff-py] for a little math AST so I figured I would be able to
reasonably easily port that to my new project.

[diff-py]: https://gist.github.com/tekknolagi/b587de40ea55dc9d65b70282fb58e262#file-diff-py-L531

I was mostly right. For example, here is the (fairly direct) Rust port that
turns expressions into IR instead of AST. The only difference is that instead
of pointers, nodes hold onto IDs, and they are linearized in a big
`Vec`[^munificent-bytecode] (hence `push_op` and `push_insn`).

[^munificent-bytecode]: For more reading on this, check out [Flattening
    ASTs][flattening-asts] by Adrian Sampson and [this Reddit
    comment][munificent-reddit] by Bob Nystrom of Crafting Interpreters fame.
    The comment is reproduced here:

    (quoting the OP)

    > I can imagine, while parsing, whenever you created a new node, rather
    > than allocating space just for it and giving the parent node the pointer,
    > you could push the node onto a vector or some other such growable
    > contiguous array and give the parent a reference to that spot.

    Yes, that will definitely help! Once you do that, you may consider other stepwise refinements.

    * Since subexpressions are executed first, it makes sense to have them
      earlier in the array than their parents. So instead of walking from the
      root to the leaves, walk the leaves first and then have the parents
      follow them.
    * At that point, parents no longer need references to their children.
      Instead, you just need some convenient place to store the results of the
      child evaluations. Maybe a stack.
    * Now your array of instructions doesn't need any actual links between
      them. It's just a flat list of which operations to perform.

    Ta-da, you just reinvented stack-based bytecode.


[flattening-asts]: https://www.cs.cornell.edu/~asampson/blog/flattening.html
[munificent-reddit]: https://old.reddit.com/r/ProgrammingLanguages/comments/mrifdr/treewalking_interpreters_and_cachelocality/gumsi2v/

```rust
impl Parser<'_> {
    fn parse_(&mut self, mut env: &mut Env, prec: u32) -> Result<InsnId, ParseError> {
        let mut lhs = match self.tokens.next() {
            None => return Err(ParseError::UnexpectedEof),
            Some(Token::Bool(value)) => {
                self.push_op(Opcode::Const(Value::Bool(value)))
            }
            // ...
            Some(Token::LParen) => {
                let result = self.parse_(&mut env, 0)?;
                self.expect(Token::RParen)?;
                result
            }
            Some(token) => return Err(ParseError::UnexpectedToken(token)),
        };
        while let Some(token) = self.tokens.peek() {
            let (assoc, op_prec) = match token {
                // ...
                Token::Plus => (Assoc::Any, 4),
                Token::Minus => (Assoc::Left, 4),
                Token::Star => (Assoc::Any, 5),
                // ...
                _ => break,
            };
            let token = token.clone();
            if op_prec < prec { return lhs; }
            self.tokens.next();
            let next_prec = if assoc == Assoc::Left { op_prec + 1 } else { op_prec };
            // ...
            let opcode = match token {
                Token::EqualEqual => Opcode::Equal,
                Token::BangEqual => Opcode::NotEqual,
                Token::Greater => Opcode::Greater,
                Token::GreaterEqual => Opcode::GreaterEqual,
                Token::Less => Opcode::Less,
                Token::LessEqual => Opcode::LessEqual,
                Token::Plus => Opcode::Add,
                Token::Minus => Opcode::Sub,
                Token::Star => Opcode::Mul,
                Token::ForwardSlash => Opcode::Div,
                _ => panic!("Unexpected token {token:?}"),
            };
            let rhs = self.parse_(&mut env, next_prec)?;
            lhs = self.push_insn(opcode, smallvec![lhs, rhs]);
        }
        lhs
    }
}
```

This started mostly fine (parsing `1 + 2` to an AST is very similar to parsing
to the IR) but I quickly ran into a problem: what about names?

See, evaluating a name like `abc` in the expression `1 + abc` is fine if you
have all of the environment plumbing: look it up in the `env`. In this
compiler, that means find the stack slot that we've assigned for it in this
scope and emit a load from that stack slot.

```rust
impl Parser<'_> {
    fn parse_(&mut self, mut env: &mut Env, prec: u32) -> Result<InsnId, ParseError> {
        let mut lhs = match self.tokens.next() {
            None => return Err(ParseError::UnexpectedEof),
            // ...
            Some(Token::Ident(name)) => {
                let name = self.prog.intern(&name);
                let slot = env.lookup(name)?;
                self.push_insn(Opcode::Load(slot), smallvec![self.frame()])
            }
            // ...
            Some(token) => return Err(ParseError::UnexpectedToken(token)),
        };
    }
}
```
